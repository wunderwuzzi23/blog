---
title: "Trust No AI: Prompt Injection Along the CIA Security Triad Paper"
date: 2024-12-23T16:30:53-08:00
draft: true
tags: [
     "aiml", "machine learning", "threats", "prompt injection", "prompt injection", "llm"
    ]

twitter:
  card: "summary_large_image"
  site: "@wunderwuzzi23"
  creator: "@wunderwuzzi23"
  title: "Trust No AI: Prompt Injection Along the CIA Security Triad Paper"
  description: "Happy to share that my TrustNoAI paper is now available on arxiv."
  image: "https://arxiv.org/pdf/2412.06090"
---

Happy to share that I authored the paper "Trust No AI: Prompt Injection Along The CIA Security Triad".

You can [download it from arxiv](https://arxiv.org/pdf/2412.06090).

The paper examines how prompt injection attacks can compromise **Confidentiality, Integrity, and Availability** (CIA) of AI systems, with real-world examples targeting vendors like OpenAI, Google, Anthropic and Microsoft. 

It summarizes many of the prompt injection examples I explained on this blog, and I hope it helps bridge the gap between traditional cybersecurity and academic AI/ML research, fostering stronger understanding and defenses against these emerging threats.

Cheers, 
Johann.