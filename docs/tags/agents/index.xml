<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agents on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/agents/</link>
    <description>Recent content in Agents on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2025</copyright>
    <lastBuildDate>Fri, 08 Aug 2025 01:20:58 -0700</lastBuildDate>
    <atom:link href="https://embracethered.com/blog/tags/agents/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenHands and the Lethal Trifecta: Leaking Your Agent&#39;s Secrets</title>
      <link>https://embracethered.com/blog/posts/2025/openhands-the-lethal-trifecta-strikes-again/</link>
      <pubDate>Fri, 08 Aug 2025 01:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/openhands-the-lethal-trifecta-strikes-again/</guid>
      <description>Another day, another AI data exfiltration exploit. Today we talk about OpenHands, which used to be referred to as OpenDevin initially. It&amp;rsquo;s created by All-Hands AI.&#xA;OpenHands renders images in chat, which enables zero-click data exfiltration during prompt injection attacks.&#xA;Recently Simon Willison gave this kind of attack pattern a great name, he calls it the lethal trifecta.&#xA;We discuss this specific image based attack technique frequently. Sometimes the same message has to be repeated again and again to raise awareness and become mainstream knowledge.</description>
    </item>
    <item>
      <title>AI Kill Chain in Action: Devin AI Exposes Ports to the Internet with Prompt Injection</title>
      <link>https://embracethered.com/blog/posts/2025/devin-ai-kill-chain-exposing-ports/</link>
      <pubDate>Fri, 08 Aug 2025 00:02:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/devin-ai-kill-chain-exposing-ports/</guid>
      <description>Today let&amp;rsquo;s explore Devin&amp;rsquo;s system prompt a bit more. Specifically, an interesing tool that I discovered when reading through it.&#xA;Hidden in Devinâ€™s capabilities is a tool that can open any local port to the public Internet. That means, with the right indirect prompt injection nudge, Devin can be tricked into publishing sensitive files or services for anyone to access.&#xA;This tunneling feature can be invoked without a human in the loop.</description>
    </item>
    <item>
      <title>How Devin AI Can Leak Your Secrets via Multiple Means</title>
      <link>https://embracethered.com/blog/posts/2025/devin-can-leak-your-secrets/</link>
      <pubDate>Thu, 07 Aug 2025 08:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/devin-can-leak-your-secrets/</guid>
      <description>In this post we show how an attacker can make Devin send sensitive information to third-party servers, via multiple means. This post assumes that you read the first post about Devin as well.&#xA;But here is a quick recap: During an indirect prompt injection Devin can be tricked into download malware and extract sensitive information on the machine. But there is more&amp;hellip;&#xA;Let&amp;rsquo;s explore how Devin can leak sensitive information and send it to a third-party server.</description>
    </item>
    <item>
      <title>I Spent $500 To Test Devin AI For Prompt Injection So That You Don&#39;t Have To</title>
      <link>https://embracethered.com/blog/posts/2025/devin-i-spent-usd500-to-hack-devin/</link>
      <pubDate>Wed, 06 Aug 2025 01:01:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/devin-i-spent-usd500-to-hack-devin/</guid>
      <description>Today we cover Devin AI from Cognition, the first AI Software Engineer.&#xA;We will cover Devin proof-of-concept exploits in multiple posts over the next few days. In this first post, we show how a prompt injection payload hosted on a website leads to a full compromise of Devin&amp;rsquo;s DevBox.&#xA;GitHub Issue To Remote Code Execution By planting instructions on a website or GitHub issue that Devin processes, it can be tricked to download malware and launch it.</description>
    </item>
    <item>
      <title>Amp Code: Arbitrary Command Execution via Prompt Injection Fixed</title>
      <link>https://embracethered.com/blog/posts/2025/amp-agents-that-modify-system-configuration-and-escape/</link>
      <pubDate>Tue, 05 Aug 2025 06:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/amp-agents-that-modify-system-configuration-and-escape/</guid>
      <description>Sandbox-escape-style attacks can happen when an AI is able to modify its own configuration settings, such as by writing to configuration files.&#xA;That was the case with Amp, an agentic coding tool built by Sourcegraph.&#xA;The AI coding agent could update its own configuration and:&#xA;Allowlist bash commands or Add a malicious MCP server on the fly to run arbitrary code This could have been exploited by the model itself, or during an indirect prompt injection attack as we will demonstrate in this post.</description>
    </item>
    <item>
      <title>Cursor IDE: Arbitrary Data Exfiltration Via Mermaid (CVE-2025-54132)</title>
      <link>https://embracethered.com/blog/posts/2025/cursor-data-exfiltration-with-mermaid/</link>
      <pubDate>Mon, 04 Aug 2025 00:04:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/cursor-data-exfiltration-with-mermaid/</guid>
      <description>Cursor is a popular AI code editor. In this post I want to share how I found an interesting data exfiltration issue, the demo exploits built and how it got fixed.&#xA;When using Cursor I noticed that it can render Mermaid diagrams.&#xA;Cursor Renders Mermaid Diagrams If you are not familiar with Mermaid, it has a simple syntax:&#xA;graph TD User --&amp;gt; Computer This will create a diagram as follows:</description>
    </item>
    <item>
      <title>Anthropic Filesystem MCP Server: Directory Access Bypass via Improper Path Validation</title>
      <link>https://embracethered.com/blog/posts/2025/anthropic-filesystem-mcp-server-bypass/</link>
      <pubDate>Sun, 03 Aug 2025 01:30:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/anthropic-filesystem-mcp-server-bypass/</guid>
      <description>A few months ago I was looking at the filesystem MCP server from Anthropic.&#xA;The server allows to give an AI, like Claude Desktop, access to the local filesystem to read files or edit them and so forth.&#xA;I was curious about access control and in the documentation there is a configuration setting to set allowedDirectories, which the AI should be allowed access to:&#xA;As you can see the example shows two folders being allowlisted for access.</description>
    </item>
    <item>
      <title>Turning ChatGPT Codex Into A ZombAI Agent</title>
      <link>https://embracethered.com/blog/posts/2025/chatgpt-codex-remote-control-zombai/</link>
      <pubDate>Sat, 02 Aug 2025 00:31:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/chatgpt-codex-remote-control-zombai/</guid>
      <description>Today we cover ChatGPT Codex as part of the Month of AI Bugs series.&#xA;ChatGPT Codex is a cloud-based software engineering agent that answers codebase questions, executes code, and drafts pull requests.&#xA;In particular, this post will demonstrate how Codex is vulnerable to prompt injection, and how the use of the &amp;ldquo;Common Dependencies Allowlist&amp;rdquo; for Internet access enables an attacker to recruit ChatGPT Codex into a malware botnet.&#xA;The ZombAI attack arrives at ChatGPT Codex today!</description>
    </item>
    <item>
      <title>Exfiltrating Your ChatGPT Chat History and Memories With Prompt Injection</title>
      <link>https://embracethered.com/blog/posts/2025/chatgpt-chat-history-data-exfiltration/</link>
      <pubDate>Fri, 01 Aug 2025 08:00:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/chatgpt-chat-history-data-exfiltration/</guid>
      <description>In this post we demonstrate how a bypass in OpenAI&amp;rsquo;s &amp;ldquo;safe URL&amp;rdquo; rendering feature allows ChatGPT to send personal information to a third-party server. This can be exploited by an adversary via a prompt injection via untrusted data.&#xA;If you process untrusted content, like summarizing a website, or analyze a pdf document, the author of that document can exfiltrate any information present in the prompt context, including your past chat history.</description>
    </item>
    <item>
      <title>The Month of AI Bugs 2025</title>
      <link>https://embracethered.com/blog/posts/2025/announcement-the-month-of-ai-bugs/</link>
      <pubDate>Mon, 28 Jul 2025 10:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/announcement-the-month-of-ai-bugs/</guid>
      <description>This year I spent a lot of time reviewing, exploiting and working with vendors to fix vulnerabilities in agentic AI systems.&#xA;As a result, I&amp;rsquo;m excited to announce the Month of AI Bugs 2025!&#xA;Goal Of The Initiative The main purpose of the Month of AI Bugs is to raise awareness about novel security vulnerabilities in agentic systems, primarily focusing on AI coding agents. Posts will cover both simple and advanced, sometimes even mind-boggling exploits.</description>
    </item>
    <item>
      <title>Security Advisory: Anthropic&#39;s Slack MCP Server Vulnerable to Data Exfiltration</title>
      <link>https://embracethered.com/blog/posts/2025/security-advisory-anthropic-slack-mcp-server-data-leakage/</link>
      <pubDate>Tue, 24 Jun 2025 16:00:46 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/security-advisory-anthropic-slack-mcp-server-data-leakage/</guid>
      <description>This is a security advisory for a data leakage and exfiltration vulnerability in a popular, but now deprecated and unmaintained, Slack MCP Server from Anthropic.&#xA;If you are using this MCP server, or run an &amp;ldquo;MCP Store&amp;rdquo; that hosts it, it is advised that you analyze how this threat applies to your use case and apply a patch as needed.&#xA;Anthropic&amp;rsquo;s Slack MCP Server When Anthropic introduced MCP they published reference server implementations on Github.</description>
    </item>
    <item>
      <title>AI ClickFix: Hijacking Computer-Use Agents Using ClickFix</title>
      <link>https://embracethered.com/blog/posts/2025/ai-clickfix-ttp-claude/</link>
      <pubDate>Sat, 24 May 2025 16:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/ai-clickfix-ttp-claude/</guid>
      <description>Today we are going to discuss how real-world tactics, techniques, and procedures (TTPs) apply to computer-use systems, specifically, we&amp;rsquo;ll look at ClickFix attacks. This demo was part of my presentation at the SAGAI Workshop on May 15th, 2025 in San Francisco.&#xA;It was a great workshop, with tons of interesting insights and discussions.&#xA;So, let&amp;rsquo;s talk about ClickFix, and how it applies to AI systems!&#xA;What is ClickFix? ClickFix is a social engineering technique that is being used by adversaries.</description>
    </item>
  </channel>
</rss>
