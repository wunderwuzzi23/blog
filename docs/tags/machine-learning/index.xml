<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/machine-learning/</link>
    <description>Recent content in machine learning on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2021</copyright>
    <lastBuildDate>Thu, 14 Oct 2021 00:02:00 -0700</lastBuildDate>
    
	<atom:link href="https://embracethered.com/blog/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Video: Understanding Image Scaling Attacks</title>
      <link>https://embracethered.com/blog/posts/2021/video-image-scaling-attacks/</link>
      <pubDate>Thu, 14 Oct 2021 00:02:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/video-image-scaling-attacks/</guid>
      <description>Today you are in for a special treat. Did you know that an adversary can hide a smaller image within a larger one?
This video demonstrates how a small image becomes magically visible when the computer resizes the large image, and also how to mitigate the vulnerability.

This is possible when vulnerable code uses insecure interpolation.
If you like this one check out the overall Machine Learning Attack Series.</description>
    </item>
    
    <item>
      <title>Using Microsoft Counterfit to create adversarial examples for Husky AI</title>
      <link>https://embracethered.com/blog/posts/2021/huskyai-using-azure-counterfit/</link>
      <pubDate>Mon, 16 Aug 2021 10:00:26 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/huskyai-using-azure-counterfit/</guid>
      <description>This post is part of the machine learning attack series.
It&amp;rsquo;s been a while that I did a Husky AI and offensive machine learning related post. This weekend I had some time to try out Counterfit. My goal was to understand what Counterfit is, how it works, and use it to turn Shadowbunny into a husky.
Let&amp;rsquo;s get started.
What is Counterfit? With Counterfit you can test your machine learning models and endpoints for specific adversarial attacks.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Overview </title>
      <link>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-overview/</link>
      <pubDate>Thu, 26 Nov 2020 09:00:51 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-overview/</guid>
      <description>What a journey it has been. I wrote quite a bit about machine learning from a red teaming/security testing perspective this year. It was brought to my attention to provide a conveninent &amp;ldquo;index page&amp;rdquo; with all Husky AI and related blog posts. Here it is.
Machine Learning Basics and Building Husky AI  Getting the hang of machine learning The machine learning pipeline and attacks Husky AI: Building a machine learning system MLOps - Operationalizing the machine learning model  Threat Modeling and Strategies  Threat modeling a machine learning system Grayhat Red Team Village Video: Building and breaking a machine learning system Assume Bias and Responsible AI  Practical Attacks and Defenses  Brute forcing images to find incorrect predictions Smart brute forcing Perturbations to misclassify existing images Adversarial Robustness Toolbox Basics Image Scaling Attacks Stealing a model file: Attacker gains read access to the model Backdooring models: Attacker modifies persisted model file Repudiation Threat and Auditing: Catching modifications and unauthorized access Attacker modifies Jupyter Notebook file to insert a backdoor CVE 2020-16977: VS Code Python Extension Remote Code Execution Using Generative Adversarial Networks (GANs) to create fake husky images Using Microsoft Counterfit to create adversarial examples  Miscellaneous  Participating in the Microsoft Machine Learning Security Evasion Competition - Bypassing malware models by signing binaries Husky AI Github Repo  Conclusion As you can see there are many machine learning specific attacks, but also a lot of &amp;ldquo;typical&amp;rdquo; red teaming techniques that put AI/ML systems at risk.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Generative Adversarial Networks (GANs)</title>
      <link>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-generative-adversarial-networks-gan/</link>
      <pubDate>Wed, 25 Nov 2020 19:55:15 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-generative-adversarial-networks-gan/</guid>
      <description>In this post we will explore Generative Adversarial Networks (GANs) to create fake husky images. The goal is, of course, to have &amp;ldquo;Husky AI&amp;rdquo; misclassify them as real huskies.
If you want to learn more about Husky AI visit the Overview post.
Generative Adversarial Networks One of the attacks I wanted to investigate for a while was the creation of fake images to trick Husky AI. The best approach seemed by using Generative Adversarial Networks (GANs).</description>
    </item>
    
    <item>
      <title>Assuming Bias and Responsible AI</title>
      <link>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-assume-bias-strategy/</link>
      <pubDate>Tue, 24 Nov 2020 14:00:50 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/machine-learning-attack-series-assume-bias-strategy/</guid>
      <description>There are plenty of examples of artificial intelligence and machine learning systems that made it into the news because of biased predictions and failures.
Here are a few examples on AI/ML gone wrong:
 Amazon had an AI recruiting tool which favored men over women for technical jobs The Microsoft chat bot named &amp;ldquo;Tay&amp;rdquo; which turned racist and sexist rather quickly A doctor at the Jupiter Hospital in Florida referred to IBM&amp;rsquo;s AI system for helping recommend cancer treatments as &amp;ldquo;a piece of sh*t&amp;rdquo; Facebook&amp;rsquo;s AI got someone arrested for incorrectly translating text  The list of AI failures goes on&amp;hellip;</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Repudiation Threat and Auditing</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-repudiation-threat-deny-action-machine-learning/</link>
      <pubDate>Tue, 10 Nov 2020 16:00:21 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-repudiation-threat-deny-action-machine-learning/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  In this post we are going to look at the &amp;ldquo;Repudiation Threat&amp;rdquo;, which is one of the threats often overlooked when performing threat modeling, and maybe something you would not even expect in a series about machine learning.</description>
    </item>
    
    <item>
      <title>Video: Building and breaking a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/learning-by-doing-building-and-breaking-machine-learning-red-team-hacking/</link>
      <pubDate>Thu, 05 Nov 2020 15:30:00 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/learning-by-doing-building-and-breaking-machine-learning-red-team-hacking/</guid>
      <description>My GrayHat Red Team Village talk &amp;ldquo;Learning by doing: Building and breaking a machine learning system&amp;rdquo; is now live on YouTube.
Check it out: https://www.youtube.com/watch?v=-SV80sIBhqY and smash the Like button! :D

Question? I thought of turning the content into a hands-on workshop. Let me know if that would be something that would you would attend? Trying to see if there is interest.
Cheers, Johann
Twitter: @wunderwuzzi23</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Image Scaling Attacks</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</link>
      <pubDate>Wed, 28 Oct 2020 13:00:27 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: Some of the attacks I want to investigate, learn about, and try out  A few weeks ago while preparing demos for my GrayHat 2020 - Red Team Village presentation I ran across &amp;ldquo;Image Scaling Attacks&amp;rdquo; in Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning by Erwin Quiring, et al.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Adversarial Robustness Toolbox Basics</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-adversarial-robustness-toolbox-testing/</link>
      <pubDate>Thu, 22 Oct 2020 15:00:48 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-adversarial-robustness-toolbox-testing/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: Some of the attacks I want to investigate, learn about, and try out  I wanted to explore the &amp;ldquo;Adversarial Robustness Toolbox&amp;rdquo; (ART) for a while to understand how it can be used to create adversarial examples for Husky AI.</description>
    </item>
    
    <item>
      <title>Hacking neural networks - so we don&#39;t get stuck in the matrix</title>
      <link>https://embracethered.com/blog/posts/2020/hacking-the-matrix/</link>
      <pubDate>Tue, 20 Oct 2020 12:00:41 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/hacking-the-matrix/</guid>
      <description>For GrayHat 2020 I was asked to create a short intro video for my Red Team Village talk &amp;ldquo;Learning by doing: Building and breaking a machine learning system&amp;rdquo;.
So I put my green screen to good use and recorded this short clip for Red Team Village.
Here is the link to the clip on Twitter:

Hope you like it. :)
The talk will be October, 31st 2020.
Schedule: http://redteamvillage.io/schedule</description>
    </item>
    
    <item>
      <title>CVE 2020-16977: VS Code Python Extension Remote Code Execution</title>
      <link>https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/</link>
      <pubDate>Wed, 14 Oct 2020 10:35:02 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/</guid>
      <description>While building &amp;ldquo;Husky AI&amp;rdquo; I started working a lot with Microsoft&amp;rsquo;s VS Code Python extension. It is a super convinient way to edit Jupyter Notebooks. I just use VS Code&amp;rsquo;s Remote SSH feature to get to my Linux host and work on modeling and testing there.
When threat modeling &amp;ldquo;Husky AI&amp;rdquo; I identified backdooring of third party libraries and development tools as a potential issue to be aware of.
So finding security issues in the tools is naturally something I am keeping an eye on.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Stealing a model file</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-model-stealing/</link>
      <pubDate>Sat, 10 Oct 2020 05:50:21 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-model-stealing/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  We talked about creating adversarial examples and &amp;ldquo;backdoor images&amp;rdquo; for Husky AI before. One thing that we noticed was that an adversary with model access can very efficiently come up with adversarial examples.</description>
    </item>
    
    <item>
      <title>Coming up: Grayhat Red Team Village talk about hacking a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/accouncement-learning-by-doing-hacking-machine-lerning-grayhat/</link>
      <pubDate>Fri, 09 Oct 2020 11:30:50 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/accouncement-learning-by-doing-hacking-machine-lerning-grayhat/</guid>
      <description>Excited to announce that I will be presenting at Grayhat - Red Team Village on October 31st 2020. The presentation is about my machine learning journey and how to build and break a machine learning system.
If you follow my blog, you can guess that there will be lots of discussion around &amp;ldquo;Husky AI&amp;rdquo;. The bits and pieces that make up a machine learning pipeline, and how to threat model such a system.</description>
    </item>
    
    <item>
      <title>Participating in the Microsoft Machine Learning Security Evasion Competition - Bypassing malware models by signing binaries</title>
      <link>https://embracethered.com/blog/posts/2020/microsoft-machine-learning-security-evasion-competition/</link>
      <pubDate>Tue, 22 Sep 2020 14:00:41 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/microsoft-machine-learning-security-evasion-competition/</guid>
      <description>This year one of my goals was to learn about machine learning and artificial intelligence.
I wrote about my journey before - including what classes I took and books I read, the models and systems I built and operationalized, threat modeling it to learn about practical attacks and defenses. My goal is to be knowledge enough in the AI/ML space enough to be able to help bridge the gap between research and operational red teaming - by doing practical things with life systems.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Backdooring models</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</link>
      <pubDate>Fri, 18 Sep 2020 14:59:47 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out Mitigations: Ways to prevent and detect the backdooring threat  During threat modeling we identified that an adversary might tamper with model files. From a technical point of view this means an adversary gained access to the model file used in production and is able overwrite it.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Perturbations to misclassify existing images</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-perturbation-external/</link>
      <pubDate>Wed, 16 Sep 2020 12:00:05 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-perturbation-external/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  The previous post covered some neat smart fuzzing techniques to improve generation of fake husky images.
The goal of this post is to take an existing image of the plush bunny below, modify it and have the model identify it as a husky.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Smart brute forcing</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/</link>
      <pubDate>Sun, 13 Sep 2020 09:04:09 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts. There are the two main sections of the series - more content will be added over time:
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  The previous post covered basic tests to trick the image recognition model.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Brute forcing images to find incorrect predictions</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</link>
      <pubDate>Wed, 09 Sep 2020 09:09:09 -0909</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
The previous four posts explained the architecture and how Husky AI was built, threat modeled and deployed. Now itâ€™s time to start the attacks and build mitigations. The appendix in this post shows all the attacks I want to research and perform in this series over the next few weeks/months.</description>
    </item>
    
    <item>
      <title>Threat modeling a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see all the posts, or visit the machine learning attack series overview section.
In the previous post we walked through the steps required to gather training data, build and test a model to build &amp;ldquo;Husky AI&amp;rdquo;.
This post is all about threat modeling the system to identify scenarios for attacks which we will perform in the upcoming posts.</description>
    </item>
    
    <item>
      <title>MLOps - Operationalizing the machine learning model</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-mlops-operationalize-the-model/</link>
      <pubDate>Sat, 05 Sep 2020 08:00:14 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-mlops-operationalize-the-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post we walked through the steps required to gather training data, build and test a model.
In this post we dive into &amp;ldquo;Operationalizing&amp;rdquo; the model. The scenario is the creation of Husky AI and my experiences and learnings from that.
Part 3 - Operationalizing the Husky AI model This actually took much longer than planned.</description>
    </item>
    
    <item>
      <title>Husky AI: Building a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-building-the-machine-learning-model/</link>
      <pubDate>Fri, 04 Sep 2020 12:04:29 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-building-the-machine-learning-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post we described the overall machine learning pipeline.
In this post we dive into the technical details on how I built and trained the machine learning model for Husky AI.
After reading this you should have a good understanding around the technical steps involved in building a machine learning system, and also some thoughts around what can be attacked.</description>
    </item>
    
    <item>
      <title>The machine learning pipeline and attacks</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/</link>
      <pubDate>Wed, 02 Sep 2020 12:04:29 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post I talked about good resources for learning more about artificial intelligence and machine learning in general, and how I started my journey in this space.
The next few posts will be about Husky AI.
What is Husky AI? Husky AI allows a user to upload an image, and get an answer back if the image contains a husky or not.</description>
    </item>
    
    <item>
      <title>Getting the hang of machine learning</title>
      <link>https://embracethered.com/blog/posts/2020/machine-learning-basics/</link>
      <pubDate>Tue, 01 Sep 2020 18:00:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/machine-learning-basics/</guid>
      <description>This year I have spent a lot of time studying machine learning and artificial intelligence.
To come up with good and useful attacks during operations, I figured it is time to learn the fundamentals and start using software, tools and algorithms. My goal was to build a couple of end to end machine learning systems from scratch, and then attack them.
This post describes my studying approach, materials, courses, and learnings.</description>
    </item>
    
    <item>
      <title>Red Teaming Telemetry Systems</title>
      <link>https://embracethered.com/blog/posts/2020/attacking-telemetry-and-machine-learning/</link>
      <pubDate>Wed, 12 Aug 2020 13:28:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/attacking-telemetry-and-machine-learning/</guid>
      <description>These days business decisions and feature development often is influenced heavily by telemetry information. Telemetry is baked into the programs, services and applications we use.
Companies are hungry for telemetry because with machine learning and Deep Neural Networks &amp;ldquo;data is the new oil&amp;rdquo;.
Telemetry provides insights into how users use a particular system, what features they exercise, how they configure the system, what errors they trigger and what buttons they like clicking on.</description>
    </item>
    
  </channel>
</rss>