<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Month of Ai Bugs on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/month-of-ai-bugs/</link>
    <description>Recent content in Month of Ai Bugs on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2025</copyright>
    <lastBuildDate>Sun, 03 Aug 2025 01:30:58 -0700</lastBuildDate>
    <atom:link href="https://embracethered.com/blog/tags/month-of-ai-bugs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Anthropic Filesystem MCP Server: Directory Access Bypass via Improper Path Validation</title>
      <link>https://embracethered.com/blog/posts/2025/anthropic-filesystem-mcp-server-bypass/</link>
      <pubDate>Sun, 03 Aug 2025 01:30:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/anthropic-filesystem-mcp-server-bypass/</guid>
      <description>A few months ago I was looking at the filesystem MCP server from Anthropic.&#xA;The server allows to give an AI, like Claude Desktop, access to the local filesystem to read files or edit them and so forth.&#xA;I was curious about access control and in the documentation there is a configuration setting to set allowedDirectories, which the AI should be allowed access to:&#xA;As you can see the example shows two folders being allowlisted for access.</description>
    </item>
    <item>
      <title>Turning ChatGPT Codex Into A ZombAI Agent</title>
      <link>https://embracethered.com/blog/posts/2025/chatgpt-codex-remote-control-zombai/</link>
      <pubDate>Sat, 02 Aug 2025 00:31:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/chatgpt-codex-remote-control-zombai/</guid>
      <description>Today we cover ChatGPT Codex as part of the Month of AI Bugs series.&#xA;ChatGPT Codex is a cloud-based software engineering agent that answers codebase questions, executes code, and drafts pull requests.&#xA;In particular, this post will demonstrate how Codex is vulnerable to prompt injection, and how the use of the &amp;ldquo;Common Dependencies Allowlist&amp;rdquo; for Internet access enables an attacker to recruit ChatGPT Codex into a malware botnet.&#xA;The ZombAI attack arrives at ChatGPT Codex today!</description>
    </item>
    <item>
      <title>Exfiltrating Your ChatGPT Chat History and Memories With Prompt Injection</title>
      <link>https://embracethered.com/blog/posts/2025/chatgpt-chat-history-data-exfiltration/</link>
      <pubDate>Fri, 01 Aug 2025 08:00:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/chatgpt-chat-history-data-exfiltration/</guid>
      <description>In this post we demonstrate how a bypass in OpenAI&amp;rsquo;s &amp;ldquo;safe URL&amp;rdquo; rendering feature allows ChatGPT to send personal information to a third-party server. This can be exploited by an adversary via a prompt injection via untrusted data.&#xA;If you process untrusted content, like summarizing a website, or analyze a pdf document, the author of that document can exfiltrate any information present in the prompt context, including your past chat history.</description>
    </item>
    <item>
      <title>The Month of AI Bugs 2025</title>
      <link>https://embracethered.com/blog/posts/2025/announcement-the-month-of-ai-bugs/</link>
      <pubDate>Mon, 28 Jul 2025 10:20:58 -0700</pubDate>
      <guid>https://embracethered.com/blog/posts/2025/announcement-the-month-of-ai-bugs/</guid>
      <description>This year I spent a lot of time reviewing, exploiting and working with vendors to fix vulnerabilities in agentic AI systems.&#xA;As a result, I&amp;rsquo;m excited to announce the Month of AI Bugs 2025!&#xA;Goal Of The Initiative The main purpose of the Month of AI Bugs is to raise awareness about novel security vulnerabilities in agentic systems, primarily focusing on AI coding agents. Posts will cover both simple and advanced, sometimes even mind-boggling exploits.</description>
    </item>
  </channel>
</rss>
