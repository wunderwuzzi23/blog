<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>huskyai on wunderwuzzi blog</title>
    <link>https://embracethered.com/blog/tags/huskyai/</link>
    <description>Recent content in huskyai on wunderwuzzi blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2020</copyright>
    <lastBuildDate>Wed, 28 Oct 2020 13:00:27 -0700</lastBuildDate>
    
	<atom:link href="https://embracethered.com/blog/tags/huskyai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine Learning Attack Series: Image Scaling Attacks</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</link>
      <pubDate>Wed, 28 Oct 2020 13:00:27 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: Some of the attacks I want to investigate, learn about, and try out  A few weeks ago while preparing demos for my GrayHat 2020 - Red Team Village presentation I ran across &amp;ldquo;Image Scaling Attacks&amp;rdquo; in Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning by Erwin Quiring, et al.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Adversarial Robustness Toolbox Basics</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-adversarial-robustness-toolbox-testing/</link>
      <pubDate>Thu, 22 Oct 2020 15:00:48 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-adversarial-robustness-toolbox-testing/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: Some of the attacks I want to investigate, learn about, and try out  I wanted to explore the &amp;ldquo;Adversarial Robustness Toolbox&amp;rdquo; (ART) for a while to understand how it can be used to create adversarial examples for Husky AI.</description>
    </item>
    
    <item>
      <title>CVE 2020-16977: VS Code Python Extension Remote Code Execution</title>
      <link>https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/</link>
      <pubDate>Wed, 14 Oct 2020 10:35:02 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/</guid>
      <description>While building &amp;ldquo;Husky AI&amp;rdquo; I started working a lot with Microsoft&amp;rsquo;s VS Code Python extension. It is a super convinient way to edit Jupyter Notebooks. I just use VS Code&amp;rsquo;s Remote SSH feature to get to my Linux host and work on modeling and testing there.
When threat modeling &amp;ldquo;Husky AI&amp;rdquo; I identified backdooring of third party libraries and development tools as a potential issue to be aware of.
So finding security issues in the tools is naturally something I am keeping an eye on.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Stealing a model file</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-model-stealing/</link>
      <pubDate>Sat, 10 Oct 2020 05:50:21 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-model-stealing/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  We talked about creating adversarial examples and &amp;ldquo;backdoor images&amp;rdquo; for Husky AI before. One thing that we noticed was that an adversary with model access can very efficiently come up with adversarial examples.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Backdooring models</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</link>
      <pubDate>Fri, 18 Sep 2020 14:59:47 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out Mitigations: Ways to prevent and detect the backdooring threat  During threat modeling we identified that an adversary might tamper with model files. From a technical point of view this means an adversary gained access to the model file used in production and is able overwrite it.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Perturbations to misclassify existing images</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-perturbation-external/</link>
      <pubDate>Wed, 16 Sep 2020 12:00:05 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-perturbation-external/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  The previous post covered some neat smart fuzzing techniques to improve generation of fake husky images.
The goal of this post is to take an existing image of the plush bunny below, modify it and have the model identify it as a husky.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Smart brute forcing</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/</link>
      <pubDate>Sun, 13 Sep 2020 09:04:09 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts. There are the two main sections of the series - more content will be added over time:
 Overview: How Husky AI was built, threat modeled and operationalized Attacks: The attacks I want to investigate, learn about, and try out  The previous post covered basic tests to trick the image recognition model.</description>
    </item>
    
    <item>
      <title>Machine Learning Attack Series: Brute forcing images to find incorrect predictions</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</link>
      <pubDate>Wed, 09 Sep 2020 09:09:09 -0909</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see related posts.
The previous four posts explained the architecture and how Husky AI was built, threat modeled and deployed. Now itâ€™s time to start the attacks and build mitigations. The appendix in this post shows all the attacks I want to research and perform in this series over the next few weeks/months.</description>
    </item>
    
    <item>
      <title>Threat modeling a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag &amp;ldquo;huskyai&amp;rdquo; to see all the posts, or visit the overview section.
In the previous post we walked through the steps required to gather training data, build and test a model to build &amp;ldquo;Husky AI&amp;rdquo;.
This post is all about threat modeling the system to identify scenarios for attacks which we will perform in the upcoming posts.</description>
    </item>
    
    <item>
      <title>MLOps - Operationalizing the machine learning model</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-mlops-operationalize-the-model/</link>
      <pubDate>Sat, 05 Sep 2020 08:00:14 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-mlops-operationalize-the-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post we walked through the steps required to gather training data, build and test a model.
In this post we dive into &amp;ldquo;Operationalizing&amp;rdquo; the model. The scenario is the creation of Husky AI and my experiences and learnings from that.
Part 3 - Operationalizing the Husky AI model This actually took much longer than planned.</description>
    </item>
    
    <item>
      <title>Husky AI: Building a machine learning system</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-building-the-machine-learning-model/</link>
      <pubDate>Fri, 04 Sep 2020 12:04:29 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-building-the-machine-learning-model/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post we described the overall machine learning pipeline.
In this post we dive into the technical details on how I built and trained the machine learning model for Husky AI.
After reading this you should have a good understanding around the technical steps involved in building a machine learning system, and also some thoughts around what can be attacked.</description>
    </item>
    
    <item>
      <title>The machine learning pipeline and attacks</title>
      <link>https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/</link>
      <pubDate>Wed, 02 Sep 2020 12:04:29 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/</guid>
      <description>This post is part of a series about machine learning and artificial intelligence.
In the previous post I talked about good resources for learning more about artificial intelligence and machine learning in general, and how I started my journey in this space.
The next few posts will be about Husky AI.
What is Husky AI? Husky AI allows a user to upload an image, and get an answer back if the image contains a husky or not.</description>
    </item>
    
    <item>
      <title>Getting the hang of machine learning</title>
      <link>https://embracethered.com/blog/posts/2020/machine-learning-basics/</link>
      <pubDate>Tue, 01 Sep 2020 18:00:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2020/machine-learning-basics/</guid>
      <description>This year I have spent a lot of time studying machine learning and artificial intelligence.
To come up with good and useful attacks during operations, I figured it is time to learn the fundamentals and start using software, tools and algorithms. My goal was to build a couple of end to end machine learning systems from scratch, and then attack them.
This post describes my studying approach, materials, courses, and learnings.</description>
    </item>
    
  </channel>
</rss>