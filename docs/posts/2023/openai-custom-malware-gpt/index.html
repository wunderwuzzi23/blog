<!DOCTYPE html>
<html lang="en-us">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
  <meta name="description" content="When OpenAI released GPTs last month I had plans for an interesting GPT.
Malicious ChatGPT Agents The idea was to create a kind of malware GPT that forwards …" />
  <link rel="canonical" href="https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/" />
  <meta property="og:title" content=" Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Demo) &middot;  Embrace The Red" />
  <meta property="og:description" content="When OpenAI released GPTs last month I had plans for an interesting GPT.
Malicious ChatGPT Agents The idea was to create a kind of malware GPT that forwards …" />
  <meta property="og:site_name" content="Embrace The Red" />
  <meta property="og:url" content="https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/" />
  <meta property="og:type" content="article" />
  <meta property="og:article:published_time" content="2023-12-12T18:00:49-08:00" />
  <meta property="og:article:tag" content="aiml" />
  <meta property="og:article:tag" content="machine learning" />
  <meta property="og:article:tag" content="prompt injection" />
  <meta property="og:article:tag" content="ttp" />
  <meta property="og:article:tag" content="llm" />
  <meta property="og:article:tag" content="exfil" />

  <title>
     Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Demo) &middot;  Embrace The Red
  </title>

  <link rel="stylesheet" href="https://embracethered.com/blog/css/bootstrap.min.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/main.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/github.css" />
  
  <link rel="stylesheet" href="https://embracethered.com/blog/fonts/cachedfonts.css" type="text/css">
  <link rel="shortcut icon" type="image/x-icon" href="https://embracethered.com/blog/images/favicon.ico" />
  <link rel="apple-touch-icon" type="image/x-icon" href="https://embracethered.com/blog/images/favicon.ico" />
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@wunderwuzzi23">
<meta name="twitter:title" content="Shall we play a game? Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Thief GPT Demo)">
<meta name="twitter:description" content="Custom GPTs can contain malicious objectives, like trying to scam users or actively exfiltrate data while hiding as a benign game or app. This posts describes the first ever public malware GPT.">
<meta name="twitter:image" content="https://embracethered.com/blog/images/2023/thief-gpt.png">

<meta name="twitter:creator" content="@wunderwuzzi23">



  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "\"Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Demo)\"",
    "description": "\"When OpenAI released GPTs last month I had plans for an interesting GPT.\\nMalicious ChatGPT Agents The idea was to create a kind of malware GPT that forwards …\"",
    "author": {
      "@type": "Person",
      "name": "wunderwuzzi",
      "url": "https://x.com/wunderwuzzi23"
    },
    "publisher": {
      "@type": "Organization",
      "name": "\"Embrace The Red\"",
      "logo": {
        "@type": "ImageObject",
        "url": "https:\/\/embracethered.com\/blog\/images/favicon.ico"
      }
    },
    "url": "\"https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/\"",
    "datePublished": "\"2023-12-12T18:00:49-08:00\"","dateModified": "\"2023-12-12T18:00:49-08:00\"",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "\"https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/\""
    }
  }
  </script>

</head>
<body>
    <header class="global-header"  style="background-image:url( /blog/images/bg.png )">
    <section class="header-text">
      <h1><a href="https://embracethered.com/blog/">Embrace The Red</a></h1>
      
      <div class="tag-line" style="min-width:fit-content; font-weight: 400;">
        wunderwuzzi&#39;s blog
        <br><div style="color: greenyellow; font-weight:400;">learn the hacks, stop the attacks.</div> 
      </div>
      
      <div class="sns-links hidden-print">
  
  <a href="mailto:security@wunderwuzzi.net">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://twitter.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  
  
  <a href="https://github.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
  
  <a href="https://youtube.com/@embracethered" target="_blank">
    <i class="fa fa-youtube"></i>
  </a>
  
  
  
  <a href="/blog/index.xml" target="_blank">
    <i class="fa fa-rss"></i>
  </a>
</div>

      
      <a href="https://embracethered.com/blog/" class="btn-header btn-back hidden-xs">
        <i class="fa fa-angle-left" aria-hidden="true"></i>
        &nbsp;Home
      </a>
      
    
      <a href="/blog/index.xml" class="btn-header btn-rss hidden-xs">
        <i class="fa fa-rss" aria-hidden="true"></i>
        &nbsp;RSS
      </a>
      <a data-formkit-toggle="15376e9e24" href="https://embracethered.kit.com/15376e9e24" class="btn-header btn-subscribe hidden-xs">
        <i class="fa fa-envelope" aria-hidden="true"></i>
        &nbsp;Subscribe
      </a>
    </section>
  </header>
  <main class="container">


<article>
  <header>
    <h1 class="text-primary">Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Demo)</h1>
    <div class="post-meta clearfix">
    
      <div class="post-date pull-left">
        Posted on
        <time datetime="2023-12-12T18:00:49-08:00">
          Dec 12, 2023
        </time>
      </div>
    
      <div class="pull-right">
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/aiml">#aiml</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/machine-learning">#machine learning</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/prompt-injection">#prompt injection</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/ttp">#ttp</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/llm">#llm</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/exfil">#exfil</a></span>
        
      </div>
    </div>
  </header>
  <section>
    <p>When OpenAI released <a href="https://openai.com/blog/introducing-gpts">GPTs</a> last month I had plans for an interesting GPT.</p>
<h2 id="malicious-chatgpt-agents">Malicious ChatGPT Agents</h2>
<p>The idea was to create a kind of malware GPT that forwards users&rsquo; chat messages to a third party server. It also asks users for personal information like emails and passwords.</p>
<h3 id="why-would-this-be-possible-end-to-end">Why would this be possible end to end?</h3>
<p><a href="/blog/posts/2023/chatgpt-webpilot-data-exfil-via-markdown-injection/">ChatGPT cannot guarantee to keep your conversation private or confidential</a>, because it loads images from any website. <strong>This allows data to be sent to a third party server.</strong></p>
<p>A GPT can contain instructions that ask the user for information and simply send it elsewhere. A demo proof-of-concept GPT was quickly created.</p>
<p><a href="/blog/images/2023/thief-gpt.png"><img src="/blog/images/2023/thief-gpt.png" alt="data gone gpt - demo"></a></p>
<p>To make it fun, it pretends to be a GPT that wants to play tic-tac-toe with the user.</p>
<p><a href="/blog/images/2023/thief-board.png"><img src="/blog/images/2023/thief-board.png" alt="tictactoe"></a></p>
<p>As you can see above before starting to play it asks for some personal information to ensure a good experience. Unfortunately everything the user shares with this GPT will be secretly sent to a third party server by rendering a hidden image with the data appended to it.</p>
<p><a href="/blog/images/2023/thief-exfil.png"><img src="/blog/images/2023/thief-exfil.png" alt="screenshot"></a></p>
<p>And the server indeed receives the user&rsquo;s data.</p>
<p><a href="/blog/images/2023/thief-server-1.png"><img src="/blog/images/2023/thief-server-1.png" alt="screenshot"></a></p>
<p>Scary. Watch the video below to see if it also got the user&rsquo;s password! :)</p>
<p>The final question was if it can be made available to other ChatGPT users?</p>
<h3 id="publishing-thief-gpt">Publishing Thief GPT!</h3>
<p>When creating a GPT it is initially private and can only be used by it&rsquo;s creator.</p>
<p>There are three publishing settings:</p>
<ol>
<li>Only me (private, default)</li>
<li>Anyone with a link</li>
<li>Public</li>
</ol>
<p>This is how the UI looks for publishing a GPT:</p>
<p><a href="/blog/images/2023/thief-gpt-publish-small.png"><img src="/blog/images/2023/thief-gpt-publish-small.png" alt="public with link"></a></p>
<p>When I first switched the setting to &ldquo;Anyone with Link&rdquo; or &ldquo;Public&rdquo;, I got this error:</p>
<p><a href="/blog/images/2023/malwaregpt-not-ready-for-sharing-error.png"><img src="/blog/images/2023/malwaregpt-not-ready-for-sharing-error.png" alt="Thief GPT Sharing"></a></p>
<p>OpenAI blocks publishing of certain GPTs. The first version contained words such as &ldquo;steal&rdquo; and &ldquo;malicious&rdquo; and it apparently failed &ldquo;brand and usage&rdquo; guidelines.</p>
<h3 id="updating-instructions">Updating Instructions</h3>
<p>However, as suggested it was a &ldquo;quick fix&rdquo; to modify the definition of the GPT to pass these checks. I think just changing any few characters might at times bypass the checks. I&rsquo;m pretty sure it uses an LLM to validate the instructions, so by pure chance dubios instructions might pass this check. Afterwards, it was published for anyone to use!</p>
<p>There is a note that the GPT might appear in the GPT store (when making it fully public):
<a href="/blog/images/2023/malwaregpt-may-appear-in-store.png"><img src="/blog/images/2023/malwaregpt-may-appear-in-store.png" alt="MalwareGPT in store"></a></p>
<p><strong>Automatic malware proliferation! Scary!</strong></p>
<p>To prevent the GPT showing up in the store I changed the setting back to &ldquo;Anyone with link&rdquo;.</p>
<p><a href="/blog/images/2023/thief-gpt-published.png"><img src="/blog/images/2023/thief-gpt-published.png" alt="published"></a></p>
<h2 id="demo-video">Demo Video</h2>
<p>If you read that far I&rsquo;m sure you want to see the demo:</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/XqKhit4GSJQ?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p><span> </span></p>
<p>Malicious Agents can scam users, ask for personal information and also exfiltrate information.</p>
<p><strong>This should be pretty alarming.</strong></p>
<h2 id="disclosure">Disclosure</h2>
<p>This GPT and underlying instructions were promptly reported to OpenAI on November, 13th 2023. However, the ticket was closed on November 15th as &ldquo;Not Applicable&rdquo;. Two follow up inquiries remained unanswered. Hence it seems best to share this with the public to raise awareness.</p>
<p>The data exfiltration technique used by the GPT (rendering hidden image markdown) was first reported to OpenAI early April 2023.</p>
<h2 id="conclusions">Conclusions</h2>
<p>There are security vulnerabilities in ChatGPT, including GPTs, that remain unaddressed:</p>
<ol>
<li><strong>GPTs can be designed as malicious agents</strong> that try to scam users</li>
<li><strong>GPTs can steal user data by exfiltrating it to external servers</strong> without the users&rsquo;s knowledge or consent</li>
<li><strong>Bypassing the current validation checks is trivial</strong>, allowing anyone to publish malicious GPTs to the world.</li>
</ol>
<p><strong>Because of the image markdown rendering vulnerability, OpenAI cannot guarantee the privacy and confidentiality of your ChatGPT conversations. This includes, but is not limited to custom GPTs.</strong></p>
<p><a href="/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/">Bing Chat</a>, <a href="/blog/posts/2023/google-bard-data-exfiltration/">Google Bard</a>, Anthropic Claude and many others fixed such issues after being made aware of them. Let&rsquo;s hope fixes get implemented, so we can safely enjoy using GPTs.</p>
<h2 id="chaos-communication-congress">Chaos Communication Congress</h2>
<p>I will be at the <a href="https://events.ccc.de/en/category/37c3/">37th Chaos Communication Congress</a> in Hamburg speaking about security issues in LLM applications to raise awareness of emerging attack techniques and what can be done to mitigate them.</p>
<p>Come by and check out the talk, it&rsquo;s called <strong>&ldquo;NEW IMPORTANT INSTRUCTIONS&rdquo;</strong>.</p>
<p>That&rsquo;s it for today. Thanks for reading.</p>
<h2 id="appendix">Appendix</h2>
<h3 id="demo-screenshot">Demo Screenshot</h3>
<p>Here are some demo screenshots:</p>
<ol>
<li>
<p>Rendering of the exfiltration request in action:
<a href="/blog/images/2023/thief-exfil.png"><img src="/blog/images/2023/thief-exfil.png" alt="screenshot"></a></p>
</li>
<li>
<p>End to end (showing the image tag after rendering, plus the data exfil)
<a href="/blog/images/2023/thief-exfil2.png"><img src="/blog/images/2023/thief-exfil2.png" alt="screenshot"></a></p>
</li>
</ol>
<h3 id="references">References</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=L_1plTXF-FE&amp;t=27s">Video: Data Exfiltration Vulnerabilities in LLM apps</a></li>
<li><a href="https://twitter.com/wunderwuzzi23/status/1704198612039737845">Indirect Prompt Injections with Google Bard</a></li>
<li><a href="https://ekoparty.org/eko2023-agenda/indirect-prompt-injections-in-the-wild-real-world-exploits-and-mitigations/">Ekoparty 2023 Prompt Injection Talk</a></li>
<li><a href="https://embracethered.com/blog/posts/2023/anthropic-fixes-claude-data-exfiltration-via-images/">Anthropic Claude Data Exfil Fix</a></li>
<li><a href="/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/">Microsoft Bing Chat Data Exfiltration Fix</a></li>
<li><a href="/blog/posts/2023/chatgpt-webpilot-data-exfil-via-markdown-injection/">ChatGPT Markdown Injection to Data Exfil Vulnerability</a></li>
<li><a href="https://events.ccc.de/en/category/37c3/">37c3 - unlocked</a></li>
</ul>

  </section>
  <footer>
    
    
    
    <footer></footer><hr/>
    
    <ul class="pager">
      
      <li class="next"><a href="https://embracethered.com/blog/posts/2023/openai-data-exfiltration-first-mitigations-implemented/">Newer <span aria-hidden="true">&rarr;</span></a></li>
      
      
      <li class="author-contact">
        <a href="mailto:security@wunderwuzzi.net">
          <i class="fa fa-envelope-o" aria-hidden="true"></i>
          &nbsp;Contact me
        </a>
     </li>

      
      
      <li class="previous"><a href="https://embracethered.com/blog/posts/2023/ekoparty-prompt-injection-talk/"><span aria-hidden="true">&larr;</span> Older</a></li>
      
    </ul>
  </footer>
</article>
</main>
  <footer class="container global-footer">
    <div class="copyright-note pull-left">
     
     (c) WUNDERWUZZI 2018-2026
     <div class="sns-links hidden-print">
  
  <a href="mailto:security@wunderwuzzi.net">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://twitter.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  
  
  <a href="https://github.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
  
  <a href="https://youtube.com/@embracethered" target="_blank">
    <i class="fa fa-youtube"></i>
  </a>
  
  
  
  <a href="/blog/index.xml" target="_blank">
    <i class="fa fa-rss"></i>
  </a>
</div>
 
     <div style="font-size:small;font-style: italic;color:crimson">
    Disclaimer: Penetration testing requires authorization from proper stakeholders. Information on this blog is provided for research and educational purposes to advance understanding of attacks and countermeasures to help secure the Internet. | <a href="https://embracethered.com/blog/privacy.txt">Privacy</a>
    </div>
    </div>
</footer>
  <script src="https://embracethered.com/blog/js/highlight.pack.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  
  



<script type="text/javascript">
  var _paq = window._paq || [];
  _paq.push(["disableCookies"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//wuzzi.net/anamato/inc/";
    _paq.push(['setTrackerUrl', u+'rts.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'rts.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<img src="https://wuzzi.net/anamato/inc/rts.php?idsite=1&amp;rec=1" style="border:0;" alt="" />


<div class="kit-subscribe-wrapper">
  <script async data-uid="15376e9e24" src="https://embracethered.kit.com/15376e9e24/index.js"></script>
</div>

</body>
</html>

