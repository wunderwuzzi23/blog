<!DOCTYPE html>
<html lang="en-us">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
  <meta name="description" content=" Recently, many of our favorite AI chatbots have gotten autonomous research capabilities. This allows the AI to go off for an extended period of time, while â€¦" />
  <link rel="canonical" href="https://embracethered.com/blog/posts/2025/chatgpt-deep-research-connectors-data-spill-and-leaks/" />
  <meta property="og:title" content=" How Deep Research Agents Can Leak Your Data &middot;  Embrace The Red" />
  <meta property="og:description" content=" Recently, many of our favorite AI chatbots have gotten autonomous research capabilities. This allows the AI to go off for an extended period of time, while â€¦" />
  <meta property="og:site_name" content="Embrace The Red" />
  <meta property="og:url" content="https://embracethered.com/blog/posts/2025/chatgpt-deep-research-connectors-data-spill-and-leaks/" />
  <meta property="og:type" content="article" />
  <meta property="og:article:published_time" content="2025-08-24T18:03:35-07:00" />
  <meta property="og:article:tag" content="llm" />
  <meta property="og:article:tag" content="agents" />
  <meta property="og:article:tag" content="month of ai bugs" />

  <title>
     How Deep Research Agents Can Leak Your Data &middot;  Embrace The Red
  </title>

  <link rel="stylesheet" href="https://embracethered.com/blog/css/bootstrap.min.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/main.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://embracethered.com/blog/css/github.css" />
  
  <link rel="stylesheet" href="https://embracethered.com/blog/fonts/cachedfonts.css" type="text/css">
  <link rel="shortcut icon" type="image/x-icon" href="https://embracethered.com/blog/images/favicon.ico" />
  <link rel="apple-touch-icon" type="image/x-icon" href="https://embracethered.com/blog/images/favicon.ico" />
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@wunderwuzzi23">
<meta name="twitter:title" content="How Deep Research Agents Can Leak Your Data">
<meta name="twitter:description" content="When enabling Deep Research an agent might go off for a long period of time and invoke many tools and leak information from one tool to another.">
<meta name="twitter:image" content="https://embracethered.com/blog/images/2025/episode24-yt.png">

<meta name="twitter:creator" content="@wunderwuzzi23">



  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "\"How Deep Research Agents Can Leak Your Data\"",
    "description": "\" Recently, many of our favorite AI chatbots have gotten autonomous research capabilities. This allows the AI to go off for an extended period of time, while â€¦\"",
    "author": {
      "@type": "Person",
      "name": "wunderwuzzi",
      "url": "https://x.com/wunderwuzzi23"
    },
    "publisher": {
      "@type": "Organization",
      "name": "\"Embrace The Red\"",
      "logo": {
        "@type": "ImageObject",
        "url": "https:\/\/embracethered.com\/blog\/images/favicon.ico"
      }
    },
    "url": "\"https://embracethered.com/blog/posts/2025/chatgpt-deep-research-connectors-data-spill-and-leaks/\"",
    "datePublished": "\"2025-08-24T18:03:35-07:00\"","dateModified": "\"2025-08-24T18:03:35-07:00\"",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "\"https://embracethered.com/blog/posts/2025/chatgpt-deep-research-connectors-data-spill-and-leaks/\""
    }
  }
  </script>

</head>
<body>
    <header class="global-header"  style="background-image:url( /blog/images/bg.png )">
    <section class="header-text">
      <h1><a href="https://embracethered.com/blog/">Embrace The Red</a></h1>
      
      <div class="tag-line" style="min-width:fit-content; font-weight: 400;">
        wunderwuzzi&#39;s blog
        <br><div style="color: greenyellow; font-weight:400;">learn the hacks, stop the attacks.</div> 
      </div>
      
      <div class="sns-links hidden-print">
  
  <a href="mailto:security@wunderwuzzi.net">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://twitter.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  
  
  <a href="https://github.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
  
  <a href="https://youtube.com/@embracethered" target="_blank">
    <i class="fa fa-youtube"></i>
  </a>
  
  
  
  <a href="/blog/index.xml" target="_blank">
    <i class="fa fa-rss"></i>
  </a>
</div>

      
      <a href="https://embracethered.com/blog/" class="btn-header btn-back hidden-xs">
        <i class="fa fa-angle-left" aria-hidden="true"></i>
        &nbsp;Home
      </a>
      
    
      <a href="/blog/index.xml" class="btn-header btn-subscribe hidden-xs">
        <i class="fa fa-rss" aria-hidden="true"></i>
        &nbsp;RSS
      </a>
    </section>
  </header>
  <main class="container">


<article>
  <header>
    <h1 class="text-primary">How Deep Research Agents Can Leak Your Data</h1>
    <div class="post-meta clearfix">
    
      <div class="post-date pull-left">
        Posted on
        <time datetime="2025-08-24T18:03:35-07:00">
          Aug 24, 2025
        </time>
      </div>
    
      <div class="pull-right">
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/llm">#llm</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/agents">#agents</a></span>
        
        <span class="post-tag small"><a href="https://embracethered.com/blog//tags/month-of-ai-bugs">#month of ai bugs</a></span>
        
      </div>
    </div>
  </header>
  <section>
    
<a id="top_ref"></a>

<p>Recently, many of our favorite AI chatbots have gotten autonomous research capabilities. This allows the AI to go off for an extended period of time, while having access to tools, such as web search, integrations, connectors and also custom-built MCP servers.</p>
<p><a href="/blog/images/2025/episode24-yt.png"><img src="/blog/images/2025/episode24-yt.png" alt="Episode 24"></a></p>
<p>This post will explore and explain in detail how there can be data spill between connected tools during Deep Research. The research is focused on ChatGPT but applies to other Deep Research agents as well.</p>
<p>With ChatGPT it&rsquo;s now possible to implement custom ChatGPT Connectors, but they have to follow very specific schema definitions, namely it requires two MCP tools created, <code>search</code> and <code>fetch</code>.</p>
<p>When I implemented my first custom Connector, which is technically an MCP server, I got this error when trying to add it to ChatGPT:</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-violate-guidelines.png"><img src="/blog/images/2025/chatgpt-deepresearch-violate-guidelines.png" alt="Research Violates Guidelines"></a></p>
<p>The server has to implement exactly <code>search</code> and <code>fetch</code>. Anything else, and the Connector will be rejected for violating guidelines.</p>
<p>With terms like <code>search</code> and <code>fetch</code> it appears that an agent will only retrieve data, but that doesn&rsquo;t mean that no data-leakage will occur as we will demonstrate in this post.</p>
<p>This research was conducted about two months ago, so a few things might have changed, but the core principles remain true.</p>
<h2 id="querying-leaks-data">Querying Leaks Data!</h2>
<p>One thing that is probably obvious to some, but maybe less obvious to others, is that all these integration and tools that technically in the same trust boundary.</p>
<p><strong>What does that mean?</strong></p>
<p>It means that data accessible to the agent from one source, can be leaked to other sources when it performs deep research queries.</p>
<p>And if there is an attacker in the loop such leaks can be forced via prompt injection.</p>
<h2 id="chatgpt-connectors-and-deep-research">ChatGPT Connectors and Deep Research</h2>
<p>The primary goal of this research post is to highlight that there is no trust boundary, and once you add multiple research tools to the research process, the agent can freely invoke tools and may use data from one to query another.</p>
<p>The ChatGPT <a href="https://help.openai.com/en/articles/11487775-connectors-in-chatgpt">documentation</a> states:</p>
<blockquote>
<p>When you enable a connector, ChatGPT can send and retrieve information from the connected app in order to find information relevant to your prompts and use them in its responses.</p></blockquote>
<p>This basically hints to this behavior.</p>
<h3 id="implementing-a-remote-mcp-server">Implementing a Remote MCP Server</h3>
<p>To test this out I created a simple remote MCP server named <code>Remote Matrix</code> that correctly implements <code>search</code> and <code>fetch</code> tools to adhere to OpenAIâ€™s specification.</p>
<p>I also <a href="https://github.com/wunderwuzzi23/remote-matrix-mcp">published the source code</a> on GitHub. It includes extensive logging, because that was my primary goal to better understand what data is sent by the AI to the MCP server.</p>
<p>The code might also be helpful because I noticed that OpenAI&rsquo;s <a href="https://github.com/kwhinnery-openai/sample-deep-research-mcp">demo Connector</a> does not correctly implement the correct schema that OpenAI Deep Research highlights in the docs.</p>
<h2 id="data-leakage-scenarios">Data Leakage Scenarios</h2>
<p>The easiest way to understand this is probably just by looking at this screenshot:</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-soures.png"><img src="/blog/images/2025/chatgpt-deepresearch-sources.png" alt="Research Spill Idea"></a></p>
<p>Here you can see we have <code>Outlook Email</code>, the <code>Remote Matrix</code> and a few other tools selected. This means that data from Outlook can be used in a query to the <code>Remote Matrix</code> tool. Remember, a research process often runs for 10+ minutes, so humans are not in the loop during the process.</p>
<p>The documentation highlights this with Web Search:</p>
<blockquote>
<p>ChatGPT can also use relevant information accessed from Connectors to inform search queries when ChatGPT searches the web to provide a response.</p></blockquote>
<p>And turns out that web search uses both <a href="https://help.openai.com/en/articles/9237897-chatgpt-search">Bing and Shopify</a>.</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-search-explain.png"><img src="/blog/images/2025/chatgpt-deepresearch-search-explain.png" alt="Remote Matrix Leak"></a></p>
<p>And as you can see above, your <strong>stored memories might also be sent to tools</strong>.</p>
<h2 id="demonstration">Demonstration</h2>
<p>For the demo I used this research prompt, and connected the Linear and Remote Matrix tools as sources:</p>
<pre tabindex="0"><code>Compile a list of all currently open issues and give and 
update in a table form with high level details and status.
</code></pre><p>The research agent first proposes a plan and asks a few follow-up questions to clarify the task. In this case it had asked me if it should search both of the connected sources.</p>
<h3 id="prompt-injection-to-force-leakage">Prompt Injection To Force Leakage</h3>
<p>To increase the likelihood of data leakage happening I created the following scenarios to hijack the AI Agent and create a confused deputy with an indirect prompt injection. There are a couple of places I tried:</p>
<ol>
<li><strong>Linear tickets with instructions</strong></li>
</ol>
<p><a href="/blog/images/2025/chatgpt-deepresearch-tool-linear2.png"><img src="/blog/images/2025/chatgpt-deepresearch-linear2.png" alt="Research Malicious Linear Ticket"></a>
2. <strong><code>Remote Matrix</code> tool with malicious tool description</strong></p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-tool-description.png"><img src="/blog/images/2025/chatgpt-deepresearch-tool-description.png" alt="Research Malicious Tool Description - Caveman"></a></p>
<p>In the following demo screenshot you can see that ChatGPT started sending queries to the <code>Remote Matrix</code> MCP server in the voice of a caveman, which was part of a prompt injection in the tool description. ðŸ˜Š</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-caveman.png"><img src="/blog/images/2025/chatgpt-deepresearch-caveman.png" alt="Research Caveman"></a></p>
<p>However, more importantly, ChatGPT sent sensitive information from the Linear tickets to the <code>Remote Matrix</code> MCP server as well:</p>
<p><a href="/blog/images/2025/chatgpt-deep-research-leak.png"><img src="/blog/images/2025/chatgpt-deep-research-leak.png" alt="Remote Matrix Leak"></a></p>
<p>As a user you can see the individual steps the agent takes in the activity pane:</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-details.png"><img src="/blog/images/2025/chatgpt-deepresearch-details.png" alt="Research Linear Ticket"></a></p>
<p>What was interesting to observe was that the agent actually combined the information of the prod service and credentials from multiple tickets into a single query.</p>
<h3 id="unintended-prompt-injection">Unintended Prompt Injection</h3>
<p>Furthermore, there was an older prompt injection test I had in a Linear ticket that I had used when testing Devin, and that ticket also influenced ChatGPT&rsquo;s research process and <strong>it seemed to start looking for a Slack tool to post a message!</strong></p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-invoke-tool.png"><img src="/blog/images/2025/chatgpt-deepresearch-invoke-tool.png" alt="Research Linear Ticket"></a></p>
<p>This is how accidents happen.</p>
<h2 id="what-about-other-deep-research-offerings">What About Other Deep Research Offerings</h2>
<p>The same concepts apply to other research agents with the same design patterns, and connection to tools.</p>
<p>OpenAI actually seems to have considered threats around custom Connectors and requires a specific implementation pattern (e.g. with <code>search</code> and <code>fetch</code> tools implemented). That means the agent does not get exposed to tools that directly manipulate or delete data.</p>
<h2 id="mitigations">Mitigations</h2>
<ul>
<li>When configuring integrations (tools), be careful which ones you simultaneously enable, as there will be spillover of information (leakage)</li>
<li>Do not connect sensitive data sources with low integrity data sources in the same research process (e.g. Outlook Email and Random MCP Server from Github), also consider if sharing with Bing/Shopify is within your risk tolerance before enabling &ldquo;Search&rdquo;</li>
<li>Deep Research is autonomous. So, considering a secure setup before launching, is crucial: Only enable sources and tools that you trust and that you feel comfortable that the data might get shared by the agent between various connected tools (Bing, custom tools,&hellip;)</li>
<li>Make sure you are okay with the privacy and data protection policies of various tools you add. Tools may receive data originating from other tool invocations (e.g. ChatGPT uses Bing and Shopify for search), and this can include sensitive information like memory or chat history.</li>
<li>If your research agent can connect to any aribtrary tool, be careful exposing data manipulation and deletion tools. OpenAI attempted to mitigate this by requiring a custom tool to have only <code>search</code> and <code>fetch</code> tools implemented.</li>
<li>Be careful with third party connectors, as those can have additional side-effects and will also receive data as part of research and prompt injection from tools can influence and hijack AI</li>
<li>In ChatGPT you can see which tools are invoked and what data is sent to them on the right summary pane. This  gives an approximate idea what the agent is doing.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>This post demonstrates that Deep Research integrations, including ChatGPT Connectors, operate within a shared trust boundary of the agent. This means that data from one source can be sent to other sources by the agent. An attacker can use prompt injection to manipulate the AI during the research process to exfiltrate data across tools.</p>
<p>This highlights the risks with taking the human out of the loop, which appears to be increasingly more common.</p>
<p>As user carefully connect only trusted data sources and be aware that data might leak from one to the other, and that an adversary could influence this with an indirect prompt injection attack.</p>
<p>The primary purpose of this post was just to demonstrate to myself that leakage between data sources can occur. I think there is a lot more research needed in this space to figure out how an attacker can influence autonomous research agents.</p>
<h2 id="appendix">Appendix</h2>
<p>One of the Linear tickets with the information that was leaked:</p>
<p><a href="/blog/images/2025/chatgpt-deepresearch-tool-linear-1.png"><img src="/blog/images/2025/chatgpt-deepresearch-linear-1.png" alt="Research Data Prod Linear Ticket"></a></p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/wunderwuzzi23/remote-matrix-mcp">Remote Matrix MCP Server</a></li>
<li><a href="https://platform.openai.com/docs/mcp">OpenAI: MCP Server Documentation</a></li>
<li><a href="https://help.openai.com/en/articles/11487775-connectors-in-chatgpt">ChatGPT Connectors</a></li>
</ul>

  </section>
  <footer>
    
    
    
    <footer></footer><hr/>
    
    <ul class="pager">
      
      <li class="next"><a href="https://embracethered.com/blog/posts/2025/manus-ai-kill-chain-expose-port-vs-code-server-on-internet/">Newer <span aria-hidden="true">&rarr;</span></a></li>
      
      
      <li class="author-contact">
        <a href="mailto:security@wunderwuzzi.net">
          <i class="fa fa-envelope-o" aria-hidden="true"></i>
          &nbsp;Contact me
        </a>
     </li>

      
      
      <li class="previous"><a href="https://embracethered.com/blog/posts/2025/windsurf-sneaking-invisible-instructions-for-prompt-injection/"><span aria-hidden="true">&larr;</span> Older</a></li>
      
    </ul>
  </footer>
</article>
</main>
  <footer class="container global-footer">
    <div class="copyright-note pull-left">
     
     (c) WUNDERWUZZI 2018-2026
     <div class="sns-links hidden-print">
  
  <a href="mailto:security@wunderwuzzi.net">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://twitter.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  
  
  <a href="https://github.com/wunderwuzzi23" target="_blank">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
  
  <a href="https://youtube.com/@embracethered" target="_blank">
    <i class="fa fa-youtube"></i>
  </a>
  
  
  
  <a href="/blog/index.xml" target="_blank">
    <i class="fa fa-rss"></i>
  </a>
</div>
 
     <div style="font-size:small;font-style: italic;color:crimson">
    Disclaimer: Penetration testing requires authorization from proper stakeholders. Information on this blog is provided for research and educational purposes to advance understanding of attacks and countermeasures to help secure the Internet. 
    </div>
    </div>
</footer>
  <script src="https://embracethered.com/blog/js/highlight.pack.js"></script>
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  
  



<script type="text/javascript">
  var _paq = window._paq || [];
  _paq.push(["disableCookies"]);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//wuzzi.net/anamato/inc/";
    _paq.push(['setTrackerUrl', u+'rts.php']);
    _paq.push(['setSiteId', '1']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'rts.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<img src="https://wuzzi.net/anamato/inc/rts.php?idsite=1&amp;rec=1" style="border:0;" alt="" />
  
</body>
</html>

